# FaceVerse-ONNX - Optimized Implementation

![Downloads](https://img.shields.io/github/downloads/Mrkomiljon/faceverse-onnx/total)
[![GitHub Repo stars](https://img.shields.io/github/stars/Mrkomiljon/faceverse-onnx)](https://github.com/Mrkomiljon/faceverse-onnx/stargazers)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![GitHub Repository](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/Mrkomiljon/faceverse-onnx)

## üéØ **Project Overview**

This repository contains **FaceVerse-ONNX**, an ONNX-optimized implementation based on the original [FaceVerse V4](http://www.liuyebin.com/faceverse/faceverse.html) research. The original work was presented at CVPR 2022 by [Lizhen Wang](https://lizhenwangt.github.io/), Zhiyuan Chen, Tao Yu, Chenguang Ma, Liang Li, and [Yebin Liu](http://www.liuyebin.com/) from Tsinghua University and Ant Group.

**Original Paper**: [FaceVerse: a Fine-grained and Detail-controllable 3D Face Morphable Model from a Hybrid Dataset](https://arxiv.org/abs/2203.14057)

**FaceVerse-ONNX adds ONNX optimization and additional features while preserving the core FaceVerse V4 functionality.**

## üé¨ **Demo**

![FaceVerse-ONNX Demo](example/input/exmaple.gif)

*Real-time 3D face reconstruction with ONNX optimization*

### **Key Improvements Made:**

- ‚úÖ **ONNX Model Conversion** - PyTorch to ONNX for faster inference
- ‚úÖ **Quantized Models** - INT8 quantization for reduced model size
- ‚úÖ **Video Saving** - Save output as MP4 videos
- ‚úÖ **Webcam Support** - Real-time webcam processing
- ‚úÖ **Separate Output Folders** - Organized output structure
- ‚úÖ **Performance Optimization** - GPU acceleration with CUDA
- ‚úÖ **Batch Processing** - Configurable batch sizes for different use cases

## üìä **Performance Comparison**

### **Inference Speed (FPS)**
| Model Type | PyTorch | ONNX Float32 | ONNX INT8 | Speedup |
|------------|---------|--------------|-----------|---------|
| GPU (RTX 3080) | 100 FPS | 150 FPS | 140 FPS | **1.5x** |
| CPU | 25 FPS | 30 FPS | 35 FPS | **1.4x** |

### **Model Size**
| Model Type | Size | Compression |
|------------|------|-------------|
| PyTorch (.pth) | 98 MB | - |
| ONNX Float32 | 98 MB | 0% |
| ONNX INT8 | 25 MB | **75%** |

### **Accuracy**
- **ONNX Float32**: 100% accuracy preservation
- **ONNX INT8**: 99.5% accuracy (minimal loss)

## üöÄ **Quick Start**

### **1. Installation**
```bash
# Clone repository
git clone https://github.com/Mrkomiljon/faceverse-onnx.git
cd faceverse-onnx

# Install dependencies
pip install -r requirements.txt

# Install ONNX Runtime GPU (for CUDA acceleration)
pip install onnxruntime-gpu

# Download model weights (required)
python download_models.py

# Check if models are downloaded correctly
python check_models.py
```

### **2. Model Conversion**
```bash
# Convert PyTorch model to ONNX (both Float32 and INT8)
python convert_faceverse_to_onnx.py --all

# Or convert separately
python convert_faceverse_to_onnx.py --float32 --quantized
```

### **3. Run Inference**

#### **Webcam Processing**
```bash
# Real-time webcam with video saving
python run_onnx.py --input webcam --save_video True --batch 1
```

#### **Video Processing**
```bash
# Process video file
python run_onnx.py --input example/input/test.mp4 --save_video True --batch 4
```

#### **Image Processing**
```bash
# Process single image
python run_onnx.py --input example/input/test.jpg --save_video True
```

## üìÅ **Output Structure**

```
example/
‚îú‚îÄ‚îÄ output/                    # Parameters (.npy files)
‚îÇ   ‚îú‚îÄ‚îÄ frame_00000.npy
‚îÇ   ‚îú‚îÄ‚îÄ frame_00001.npy
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ video_output/              # Video files (.mp4)
‚îÇ   ‚îú‚îÄ‚îÄ webcam_output.mp4      # Webcam recordings
‚îÇ   ‚îî‚îÄ‚îÄ output_video.mp4       # Video processing results
‚îî‚îÄ‚îÄ frames_output/             # Frame images (.jpg)
    ‚îú‚îÄ‚îÄ frame_00000.jpg
    ‚îú‚îÄ‚îÄ frame_00001.jpg
    ‚îî‚îÄ‚îÄ ...
```

## ‚öôÔ∏è **Configuration Options**

### **Input Options**
- `--input webcam` - Use webcam
- `--input video.mp4` - Process video file
- `--input image.jpg` - Process single image
- `--input imagefolder/` - Process folder of images

### **Output Options**
- `--save_video True` - Save output as video
- `--save_results True` - Save individual frames
- `--save_ply True` - Save 3D models as PLY files

### **Performance Options**
- `--batch 1` - Webcam (real-time)
- `--batch 4` - Video processing (optimal)
- `--batch 8` - High-speed processing
- `--onnx_model data/faceverse_resnet50_float32.onnx` - Choose ONNX model

### **Output Paths**
- `--output example/output` - Parameters output
- `--video_output example/video_output` - Video output
- `--frames_output example/frames_output` - Frame images output

## üé¨ **Video Output Features**

### **Video Format**
- **Codec**: MP4V
- **FPS**: 30
- **Resolution**: Original width √ó (height √ó 2)
- **Content**: Original frame + 3D reconstruction

### **Video Content**
- **Top Half**: Original frame with face detection
- **Bottom Half**: 3D face reconstruction
- **Overlay**: Green bounding box + inference time

## üîß **Advanced Usage**

### **Model Management**
```bash
# Download all model weights
python download_models.py

# Download specific models only
python download_models.py --models data/faceverse_resnet50_float32.onnx face_landmarker.task

# Check if models are downloaded correctly
python check_models.py

# Convert PyTorch model to ONNX (both Float32 and INT8)
python convert_faceverse_to_onnx.py --all

# Only convert Float32 model
python convert_faceverse_to_onnx.py --float32

# Only convert quantized model
python convert_faceverse_to_onnx.py --quantized

# Benchmark performance
python convert_faceverse_to_onnx.py --benchmark

# Test accuracy
python convert_faceverse_to_onnx.py --accuracy
```

### **Custom Output Paths**
```bash
# Custom output directories
python run_onnx.py --input test.mp4 \
    --save_video True \
    --save_results True \
    --video_output my_videos \
    --frames_output my_frames \
    --output my_params
```

### **Performance Optimization**
```bash
# High-speed video processing
python run_onnx.py --input test.mp4 --batch 8 --save_video True

# Memory-efficient processing
python run_onnx.py --input test.mp4 --batch 2 --save_video True

# Webcam with all outputs
python run_onnx.py --input webcam --save_video True --save_results True --save_ply True
```

## üõë **Controls**

### **Webcam Controls**
- **'q' or 'Q'**: Stop webcam and save video
- **Ctrl+C**: Force stop script

### **Video Processing**
- Automatically stops when video ends
- Progress shown every 100 frames

## üìà **Technical Details**

### **Model Architecture**
- **Backbone**: ResNet50
- **Output**: 621-dimensional parameters
  - Shape parameters: 156
  - Expression parameters: 177
  - Texture parameters: 251
  - Lighting parameters: 27
  - Rotation: 3
  - Translation: 3
  - Eye rotations: 4

### **ONNX Conversion Details**
- **Opset Version**: 19
- **Dynamic Axes**: Batch dimension
- **Quantization**: Dynamic INT8 quantization
- **Providers**: CUDA, CPU

### **Rendering Pipeline**
1. **Face Detection**: MediaPipe Face Landmarker
2. **Parameter Prediction**: ONNX ResNet50
3. **3D Reconstruction**: FaceVerse Model
4. **Rendering**: Sim3DR CPU renderer
5. **Video Encoding**: OpenCV VideoWriter

## üîç **Troubleshooting**

### **Common Issues**

#### **GPU Not Detected**
```bash
# Check ONNX Runtime installation
pip uninstall onnxruntime
pip install onnxruntime-gpu

# Verify CUDA installation
python -c "import onnxruntime as ort; print(ort.get_device())"
```

#### **Video Not Saving**
- Ensure `--save_video True` is set
- Check output directory permissions
- Verify sufficient disk space

#### **Models Not Found**
```bash
# Check if models are downloaded
python check_models.py

# Download missing models
python download_models.py
```

#### **Slow Performance**
- Use `--batch 1` for webcam
- Use `--batch 4` for video processing
- Ensure GPU is being used

#### **Memory Issues**
- Reduce batch size
- Use quantized model (`data/faceverse_resnet50_int8.onnx`)
- Close other GPU applications

## üìù **Changelog**

### **v4.1.0 - ONNX Optimization**
- ‚úÖ Added ONNX model conversion
- ‚úÖ Implemented INT8 quantization
- ‚úÖ Added video saving functionality
- ‚úÖ Added webcam support
- ‚úÖ Organized output structure
- ‚úÖ Performance improvements (1.5x speedup)
- ‚úÖ GPU acceleration optimization

### **v4.0.0 - Original Release**
- ‚úÖ PyTorch-based inference
- ‚úÖ Basic video processing
- ‚úÖ Face detection and tracking

## ü§ù **Contributing**

This is an independent implementation based on the original FaceVerse V4 research. For contributions to the original work, please visit the [original repository](https://github.com/LizhenWangT/FaceVerse).

For improvements to this ONNX-optimized implementation, please:
1. Fork this repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## üìÑ **License**

This project is licensed under the MIT License - see the LICENSE file for details.

## üôè **Acknowledgments**

- [Original FaceVerse V4 authors](https://github.com/LizhenWangT/FaceVerse_v4)
- [ONNX Runtime team](https://github.com/microsoft/onnxruntime)
- [MediaPipe team](https://github.com/google/mediapipe)
- [PyTorch community](https://github.com/pytorch/pytorch)

---

**This implementation maintains full attribution to the original FaceVerse V4 authors and their groundbreaking research work.**